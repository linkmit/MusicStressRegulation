{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_json(\"../data/metadata_full.json\")\n",
    "df_audio_features = pd.read_csv(\"../outputs/df_audio_features.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "df_annotated = pd.read_csv(\"../outputs/annotated_compiled_songs_with_strategy_counts.csv\").drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated['strategy'] = df_annotated['strategy'].apply(\n",
    "    lambda s: literal_eval(s) if isinstance(s, str) and s.strip().startswith('[') else s\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge meta-data and audio features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually encode the artist and audiosourcewebpage for missing_song\n",
    "df_audio_features.loc[162, 'artist'] = 'Snarky Puppy'\n",
    "df_audio_features.loc[162, 'audiosourcewebpage'] = 'https://open.spotify.com/track/3Vj7fRefltLc0zcNnjux4e'\n",
    "df_audio_features.loc[162, 'title'] = 'Snarky Puppy - The Curtain - Live From Dordrecht, Het Energiehuis  2014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(df_m, df_af):\n",
    "    '''\n",
    "    Merge metadata and audio feature dataframes.\n",
    "    First, tries to match url's. If that fails, match on song titles.\n",
    "    '''\n",
    "\n",
    "    matching_urls = df_m[\"url\"].isin(df_af[\"audiosourcewebpage\"])\n",
    "    matching_urls_idx = df_m.index[matching_urls]\n",
    "    df_m_matching = df_m.loc[matching_urls_idx]\n",
    "    \n",
    "    missing_urls_idx = df_m.index[~matching_urls]\n",
    "    df_m_missing = df_m.loc[missing_urls_idx]\n",
    "\n",
    "    # if there are matching urls, merge based on urls\n",
    "    df_merged_urls = df_af.merge(\n",
    "        df_m_matching, how=\"inner\",\n",
    "        left_on=\"audiosourcewebpage\", right_on=\"url\"\n",
    "    )\n",
    "\n",
    "    # if there are two different urls, try to merge based on the song title\n",
    "    df_merged_title = df_af.merge(\n",
    "        df_m_missing, how=\"inner\",\n",
    "        left_on=\"title\", right_on=\"name\"\n",
    "    )\n",
    "\n",
    "    merged_all = pd.concat([df_merged_urls, df_merged_title])\n",
    "\n",
    "    return merged_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_dfs(df_meta, df_audio_features)\n",
    "\n",
    "# drop duplicated tracks\n",
    "df_merged_unique = df_merged.drop_duplicates(subset='audiosourcewebpage', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_include = [\n",
    "    # metadata\n",
    "    'url',\n",
    "    'name',\n",
    "    'artists',\n",
    "    'artist_y', # has to be renamed; should we keep both artists and artist?\n",
    "    'genres',\n",
    "    'duration',\n",
    "    'year',\n",
    "    'popularity',\n",
    "    # lowlevel features\n",
    "    'lowlevel.dissonance.mean',\n",
    "    'lowlevel.dissonance.stdev',\n",
    "    'lowlevel.dynamic_complexity',\n",
    "    'lowlevel.hfc.mean',\n",
    "    'lowlevel.hfc.stdev',\n",
    "    'lowlevel.loudness_ebu128.integrated',\n",
    "    'lowlevel.loudness_ebu128.loudness_range',\n",
    "    'lowlevel.melbands_crest.mean',\n",
    "    'lowlevel.melbands_crest.stdev',\n",
    "    'lowlevel.melbands_flatness_db.mean',\n",
    "    'lowlevel.melbands_flatness_db.stdev',\n",
    "    'lowlevel.melbands_kurtosis.mean',\n",
    "    'lowlevel.melbands_kurtosis.stdev',\n",
    "    'lowlevel.melbands_skewness.mean',\n",
    "    'lowlevel.melbands_skewness.stdev',\n",
    "    'lowlevel.melbands_spread.mean',\n",
    "    'lowlevel.melbands_spread.stdev',\n",
    "    'lowlevel.pitch_salience.mean',\n",
    "    'lowlevel.pitch_salience.stdev',\n",
    "    'lowlevel.spectral_centroid.mean',\n",
    "    'lowlevel.spectral_centroid.stdev',\n",
    "    'lowlevel.spectral_complexity.mean',\n",
    "    'lowlevel.spectral_complexity.stdev',\n",
    "    'lowlevel.spectral_decrease.mean',\n",
    "    'lowlevel.spectral_decrease.stdev',\n",
    "    'lowlevel.spectral_energy.mean',\n",
    "    'lowlevel.spectral_energy.stdev',\n",
    "    'lowlevel.spectral_flux.mean',\n",
    "    'lowlevel.spectral_flux.stdev',\n",
    "    'lowlevel.spectral_kurtosis.mean',\n",
    "    'lowlevel.spectral_kurtosis.stdev',\n",
    "    'lowlevel.spectral_rms.mean',\n",
    "    'lowlevel.spectral_rms.stdev',\n",
    "    'lowlevel.spectral_rolloff.mean',\n",
    "    'lowlevel.spectral_rolloff.stdev',\n",
    "    'lowlevel.spectral_skewness.mean',\n",
    "    'lowlevel.spectral_skewness.stdev',\n",
    "    'lowlevel.spectral_spread.mean',\n",
    "    'lowlevel.spectral_spread.stdev',\n",
    "    'lowlevel.spectral_strongpeak.mean',\n",
    "    'lowlevel.spectral_strongpeak.stdev',\n",
    "    'lowlevel.zerocrossingrate.mean',\n",
    "    'lowlevel.zerocrossingrate.stdev',\n",
    "    'lowlevel.mfcc.mean',\n",
    "    'lowlevel.spectral_contrast_coeffs.mean',\n",
    "    'lowlevel.spectral_contrast_coeffs.stdev',\n",
    "    'lowlevel.spectral_contrast_valleys.mean',\n",
    "    'lowlevel.spectral_contrast_valleys.stdev',\n",
    "    # rhythm features\n",
    "    'rhythm.beats_loudness.mean',\n",
    "    'rhythm.beats_loudness.stdev',\n",
    "    'rhythm.bpm',\n",
    "    'rhythm.danceability',\n",
    "    'rhythm.onset_rate',\n",
    "    # tonal features\n",
    "    'tonal.chords_changes_rate',\n",
    "    'tonal.chords_number_rate',\n",
    "    'tonal.chords_strength.mean',\n",
    "    'tonal.chords_strength.stdev',\n",
    "    'tonal.key_krumhansl.strength',\n",
    "    'tonal.key_krumhansl.key',\n",
    "    'tonal.key_krumhansl.scale'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_merged_unique[columns_to_include]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine columns with NaN values and remove these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowlevel.spectral_spread.mean     439\n",
      "lowlevel.spectral_spread.stdev    212\n",
      "dtype: int64\n",
      "0.42289039767216297\n"
     ]
    }
   ],
   "source": [
    "print(df_filtered.isna().sum()[df_filtered.isna().sum() > 0])\n",
    "print(len(df_filtered[df_filtered['genres'].apply(lambda x: isinstance(x, list) and len(x) == 0)])/len(df_filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered[df_filtered['genres'].apply(lambda x: isinstance(x, list) and len(x) == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_leave_out = [# due to NaN entries\n",
    "                     \"genres\",\n",
    "                     \"lowlevel.spectral_spread.mean\",\n",
    "                     \"lowlevel.spectral_spread.stdev\",\n",
    "                     # due to array-like structure\n",
    "                     \"lowlevel.spectral_contrast_coeffs.mean\",\n",
    "                     \"lowlevel.spectral_contrast_coeffs.stdev\", \n",
    "                     \"lowlevel.spectral_contrast_valleys.mean\", \n",
    "                     \"lowlevel.spectral_contrast_valleys.stdev\"]\n",
    "\n",
    "df_filtered = df_filtered.drop(columns= cols_to_leave_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feature for each value in lowlevel.mfcc.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['lowlevel.mfcc.mean'] = df_filtered['lowlevel.mfcc.mean'].apply(\n",
    "    lambda s: literal_eval(s) if isinstance(s, str) and s.strip().startswith('[') else s\n",
    ")\n",
    "\n",
    "for i in range(13):\n",
    "    df_filtered[f\"lowlevel.mfcc.mean.{i}\"] = df_filtered[\"lowlevel.mfcc.mean\"].apply(lambda x: x[i])\n",
    "\n",
    "df_filtered.drop(columns=\"lowlevel.mfcc.mean\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate each track with strateg(ies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "strategies_df = df_annotated.drop_duplicates(subset='url', keep='first')\n",
    "strategies_df = df_annotated[['url', 'strategy', 'response_id']]\n",
    "\n",
    "# Merge labels with df_filtered\n",
    "df_labeled = strategies_df.merge(df_filtered, how='right', on='url').drop_duplicates('url', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually and algorithmically find mismatching tracks and labels\n",
    "\n",
    "map_urls = {\n",
    "    \"わたしのアール\": \"私のアール\",\n",
    "    \"Deriheru Yondara Kimi ga Kita - Original Ver.\": \"デリヘル呼んだら君が来た\",\n",
    "    \"mirrorball\": \"Mirrorball\"\n",
    "}\n",
    "\n",
    "def find_missing_strategies(df_labeled, all_batches_annotated, strategies_df):\n",
    "    y = df_labeled['strategy']\n",
    "    no_label_idx = y[y.isna()].index\n",
    "    mismatching_songs = df_labeled.loc[no_label_idx].copy()\n",
    "\n",
    "    for i, row in mismatching_songs.iterrows():\n",
    "        title = row['name']\n",
    "        name_match = all_batches_annotated.loc[all_batches_annotated['song_name'] == title, 'url']\n",
    "        if len(name_match) > 0:\n",
    "            new_url = name_match.iloc[0]\n",
    "        else:\n",
    "            alt_title = map_urls[title]\n",
    "            name_match = all_batches_annotated.loc[all_batches_annotated['song_name'] == alt_title, 'url']\n",
    "            new_url = name_match.iloc[0]\n",
    "\n",
    "        df_labeled.at[i, 'url'] = new_url\n",
    "\n",
    "        m = all_batches_annotated.loc[all_batches_annotated['song_name'] == title, 'url']\n",
    "        s = strategies_df.loc[strategies_df['url'] == new_url, 'strategy']\n",
    "        if len(s) > 0:\n",
    "            new_strategy = s.iloc[0]\n",
    "        else:\n",
    "            s2 = all_batches_annotated.loc[all_batches_annotated['url'] == new_url, 'strategy']\n",
    "            new_strategy = s2.iloc[0] if len(s2) > 0 else None\n",
    "\n",
    "        df_labeled.at[i, 'strategy'] = new_strategy\n",
    "    \n",
    "    return df_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = find_missing_strategies(df_labeled, df_annotated, strategies_df)\n",
    "\n",
    "df_labeled.loc[43, 'response_id'] = \"R_2q7KRMeEj2Ki93e\"\n",
    "df_labeled.loc[132, 'response_id'] = \"R_2oS0VRFGHi3daXX\"\n",
    "df_labeled.loc[411, 'response_id'] = \"R_2oS0VRFGHi3daXX\"\n",
    "df_labeled.loc[764, 'response_id'] = \"R_8eLKaSUgqXjGFkl\"\n",
    "df_labeled.loc[831, 'response_id'] = \"R_88HQeKMOYExgqkB\"\n",
    "df_labeled.loc[897, 'response_id'] = \"R_2cD4oWRk402VtjH\"\n",
    "df_labeled.loc[922, 'response_id'] = \"R_8eLKaSUgqXjGFkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"meta.\" as a suffix to metadata columns\n",
    "meta_rename_mapping = {col: f\"meta.{col}\" for col in df_labeled.columns[5:8]}\n",
    "df_labeled = df_labeled.rename(columns=meta_rename_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled.to_csv(\"../outputs/full_dataset_without_openl3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_cleaned = df_labeled.drop(columns=[\"url\", \"response_id\", \"name\", \"artists\", \"meta.artist_y\", \"tonal.key_krumhansl.key\", \"tonal.key_krumhansl.scale\"])\n",
    "\n",
    "def process_multi_strategies(x):\n",
    "    \"\"\"\n",
    "    If songs occur more than once, but for the same strategy (e.g. [('solace', 2)]) keep the strategy\n",
    "    \"\"\"\n",
    "    if isinstance(x,str):\n",
    "        # keep current x\n",
    "        return x\n",
    "    elif isinstance(x,list) and len(x) == 1:\n",
    "        new_x = x[0][0]\n",
    "        return new_x\n",
    "    elif isinstance(x,list) and len(x) > 1:\n",
    "        return np.nan\n",
    "    \n",
    "df_labeled_cleaned['strategy'] = df_labeled_cleaned['strategy'].apply(process_multi_strategies)\n",
    "\n",
    "# drop tracks corresponding to multiple strategies\n",
    "df_labeled_cleaned = df_labeled_cleaned.dropna(subset=['strategy'])\n",
    "\n",
    "df_labeled_cleaned.to_csv(\"../data/pca_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporate Open L3 audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openl3 = pd.read_csv(\"../data/openl3_full_dataset.csv\")\n",
    "df_openl3[['artist', 'title']] = df_openl3['track_id'].str.split(' - ', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove question marks and slashes\n",
    "df_labeled_copy = df_labeled.copy()\n",
    "\n",
    "df_labeled_copy['name'] = (\n",
    "    df_labeled_copy['name']\n",
    "    .str.replace('?', '', regex=False)\n",
    "    .str.replace('/', '', regex=False)\n",
    ")\n",
    "\n",
    "df_labeled_copy['meta.artist_y'] = df_labeled_copy['meta.artist_y'].str.replace('/', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually re-encode track names \n",
    "df_labeled_copy.loc[22, 'name'] = 'The Gadfly Suite, Op. 97a- Romance'\n",
    "df_labeled_copy.loc[78, 'name'] = \"Tchaikovsky- The Nutcracker, Op. 71, Act I, Scene 1- No. 4, Dancing Scene. Arrival of Drosselmeyer\"\n",
    "df_labeled_copy.loc[91, 'name'] = \"Stay Alive - From 'The Secret Life of Walter Mitty' Soundtrack\"\n",
    "df_labeled_copy.loc[172, 'name'] = \"Mrs. Robinson - From 'The Graduate' Soundtrack\"\n",
    "df_labeled_copy.loc[225, 'name'] = \"Requiem, K. 626- Lacrimosa\"\n",
    "df_labeled_copy.loc[283, 'name'] = \"Violin Concerto No. 1- II. Crotchet = c. 108\"\n",
    "df_labeled_copy.loc[327, 'name'] = \"Moon Halo - Honkai Impact 3Rd 'Everlasting Flames' Animated Short Theme\"\n",
    "df_labeled_copy.loc[410, 'name'] = \"Piano Concerto No. 2 in C Minor, Op. 18- 2. Adagio sostenuto\"\n",
    "df_labeled_copy.loc[428, 'name'] = \"Coconut Mall (From 'Mario Kart Wii')\"\n",
    "df_labeled_copy.loc[898, 'name'] = \"Scheherazade- The Tale of the Kalendar Prince\"\n",
    "df_labeled_copy.loc[971, 'name'] = \"Liebestraume, S541R211 - No. 3- Nocturne in A-Flat Major\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Open L3 features to df_labeled\n",
    "df_af_openl3 = df_openl3.merge(df_labeled_copy, left_on=[\"artist\", \"title\"], right_on=[\"meta.artist_y\", \"name\"])\n",
    "df_af_openl3 = df_af_openl3.drop(columns=['artist', 'title', 'url', 'name', 'artists', 'meta.artist_y']).sort_index(axis=1)\n",
    "\n",
    "df_af_openl3.to_csv(\"../outputs/full_dataset_with_openl3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_l3_embeddings(df):\n",
    "    def is_l3(col):\n",
    "        if not col.startswith(\"e\"): return False\n",
    "        suf = col[1:]\n",
    "        if not suf.isdigit(): return False\n",
    "        idx = int(suf)\n",
    "        return 0 <= idx <= 511\n",
    "    cols_to_drop = [c for c in df.columns if is_l3(c)]\n",
    "    return df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "dropl3 = drop_l3_embeddings(df_af_openl3)\n",
    "dropl3 = dropl3.drop(columns=[\"track_id\", \"strategy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
