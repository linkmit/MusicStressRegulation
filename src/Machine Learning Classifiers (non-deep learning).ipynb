{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4af5678b-2fd5-4db5-ac1d-9a995b72a76a",
   "metadata": {},
   "source": [
    "**Set working directory to folder with dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734b6cfe-2cf6-42aa-952a-92915f686534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\timk\\\\OneDrive\\\\Desktop\\\\full_dataset_folder'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\timk\\\\OneDrive\\\\Desktop\\\\full_dataset_folder') # Change to your own folder structure @Linka\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a67bb-4880-43f3-866d-610b765eba6f",
   "metadata": {},
   "source": [
    "**Load and explore data files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "357a8399-5f65-4af4-8b7b-7a252f91be97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (796, 595)\n",
      "Test shape: (199, 595)\n",
      "\n",
      "Label distribution in training set:\n",
      "y\n",
      "2    0.201005\n",
      "6    0.154523\n",
      "1    0.153266\n",
      "0    0.141960\n",
      "4    0.136935\n",
      "3    0.115578\n",
      "5    0.096734\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Load data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").squeeze()\n",
    "y_test = pd.read_csv(\"y_test.csv\").squeeze()\n",
    "\n",
    "# Print exploratory dataset information\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"\\nLabel distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44a599-8e32-4240-8a6a-d554fe654e38",
   "metadata": {},
   "source": [
    "**Train two baselines: 1) majority and 2) random classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a94d8f5-e773-4216-a8de-0c7737efc6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAJORITY BASELINE\n",
      "Accuracy: 0.20100502512562815\n",
      "Macro-F1: 0.04781829049611476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.20      1.00      0.33        40\n",
      "           3       0.00      0.00      0.00        23\n",
      "           4       0.00      0.00      0.00        27\n",
      "           5       0.00      0.00      0.00        20\n",
      "           6       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.20       199\n",
      "   macro avg       0.03      0.14      0.05       199\n",
      "weighted avg       0.04      0.20      0.07       199\n",
      "\n",
      "RANDOM BASELINE\n",
      "Accuracy: 0.1708542713567839\n",
      "Macro-F1: 0.166605585836632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.18      0.19        28\n",
      "           1       0.19      0.17      0.18        30\n",
      "           2       0.23      0.15      0.18        40\n",
      "           3       0.06      0.09      0.07        23\n",
      "           4       0.21      0.22      0.22        27\n",
      "           5       0.09      0.10      0.09        20\n",
      "           6       0.22      0.26      0.24        31\n",
      "\n",
      "    accuracy                           0.17       199\n",
      "   macro avg       0.17      0.17      0.17       199\n",
      "weighted avg       0.18      0.17      0.17       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BASELINE 1: Majority classifier\n",
    "majority_baseline = DummyClassifier(strategy=\"most_frequent\")\n",
    "majority_baseline.fit(X_train, y_train)\n",
    "y_pred_majority = majority_baseline.predict(X_test)\n",
    "\n",
    "print(\"MAJORITY BASELINE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_majority))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred_majority, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred_majority, zero_division=0)) # zero_division=0 is added to avoid annoying warning\n",
    "\n",
    "# BASELINE 2: Random classifier\n",
    "random_baseline = DummyClassifier(strategy=\"uniform\", random_state=42)\n",
    "random_baseline.fit(X_train, y_train)\n",
    "y_pred_random = random_baseline.predict(X_test)\n",
    "\n",
    "print(\"RANDOM BASELINE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_random))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred_random, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred_random, zero_division=0)) # zero_division=0 is added to avoid annoying warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d85ced-5b93-4785-8389-e6772d31c9f6",
   "metadata": {},
   "source": [
    "**Train and evaluate three models: LogReg, LinearSVM, RF (DROP OPENL3 FEATURES, ONLY ESSENTIA FEATURES)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8cda49c-b4e2-4a39-b408-e2b85dba9e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (features): (796, 83) (199, 83)\n",
      "\n",
      "=== LogReg (scaled, balanced) ===\n",
      "Accuracy: 0.22110552763819097\n",
      "Macro-F1: 0.21230367287598054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.14      0.15        28\n",
      "           1       0.22      0.17      0.19        30\n",
      "           2       0.36      0.35      0.35        40\n",
      "           3       0.19      0.17      0.18        23\n",
      "           4       0.24      0.30      0.26        27\n",
      "           5       0.21      0.30      0.25        20\n",
      "           6       0.11      0.10      0.10        31\n",
      "\n",
      "    accuracy                           0.22       199\n",
      "   macro avg       0.21      0.22      0.21       199\n",
      "weighted avg       0.22      0.22      0.22       199\n",
      "\n",
      "\n",
      "=== LinearSVC (scaled, balanced) ===\n",
      "Accuracy: 0.20603015075376885\n",
      "Macro-F1: 0.19239616485518127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.11      0.12        28\n",
      "           1       0.20      0.13      0.16        30\n",
      "           2       0.37      0.38      0.37        40\n",
      "           3       0.16      0.17      0.17        23\n",
      "           4       0.21      0.26      0.23        27\n",
      "           5       0.19      0.30      0.23        20\n",
      "           6       0.09      0.06      0.07        31\n",
      "\n",
      "    accuracy                           0.21       199\n",
      "   macro avg       0.19      0.20      0.19       199\n",
      "weighted avg       0.20      0.21      0.20       199\n",
      "\n",
      "\n",
      "=== RandomForest (balanced_subsample) ===\n",
      "Accuracy: 0.3065326633165829\n",
      "Macro-F1: 0.2684927372193925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.11      0.13        28\n",
      "           1       0.20      0.13      0.16        30\n",
      "           2       0.33      0.70      0.45        40\n",
      "           3       0.40      0.26      0.32        23\n",
      "           4       0.33      0.37      0.35        27\n",
      "           5       0.43      0.15      0.22        20\n",
      "           6       0.27      0.23      0.25        31\n",
      "\n",
      "    accuracy                           0.31       199\n",
      "   macro avg       0.31      0.28      0.27       199\n",
      "weighted avg       0.30      0.31      0.28       199\n",
      "\n",
      "Summaries (sorted on macro_f1)\n",
      "                               model  test_accuracy  test_macro_f1\n",
      "2  RandomForest (balanced_subsample)       0.306533       0.268493\n",
      "0          LogReg (scaled, balanced)       0.221106       0.212304\n",
      "1       LinearSVC (scaled, balanced)       0.206030       0.192396\n",
      "\n",
      "Best params:\n",
      "- LogReg: {'clf__C': 1.0}\n",
      "- LinearSVC: {'clf__C': 0.3}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Drop L3 embeddings (vague function from ChatGPT)\n",
    "def drop_l3_embeddings(df):\n",
    "    def is_l3(col):\n",
    "        if not col.startswith(\"e\"): return False\n",
    "        suf = col[1:]\n",
    "        if not suf.isdigit(): return False\n",
    "        idx = int(suf)\n",
    "        return 0 <= idx <= 511\n",
    "    cols_to_drop = [c for c in df.columns if is_l3(c)]\n",
    "    return df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "X_train_f = drop_l3_embeddings(X_train)\n",
    "X_test_f  = drop_l3_embeddings(X_test)\n",
    "\n",
    "print(\"Shapes (features):\", X_train_f.shape, X_test_f.shape)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate(name, est):\n",
    "    est.fit(X_train_f, y_train)\n",
    "    y_pred = est.predict(X_test_f)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mf1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Macro-F1:\", mf1)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0)) # i am not exactly sure what zero division does but it helped me get rid of an annoying warning\n",
    "    return name, acc, mf1\n",
    "\n",
    "# MODEL 1: LOGISTIC REGRESSION\n",
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", LogisticRegression(max_iter=4000, class_weight=\"balanced\", solver=\"lbfgs\", random_state=42)),\n",
    "])\n",
    "gs_lr = GridSearchCV(pipe_lr, {\"clf__C\":[0.3, 1.0, 3.0]}, scoring=\"f1_macro\", cv=cv, n_jobs=-1)\n",
    "gs_lr.fit(X_train_f, y_train)\n",
    "\n",
    "# MODEL 2: LINEAR SVM\n",
    "pipe_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LinearSVC(C=1.0, class_weight=\"balanced\", random_state=42)),\n",
    "])\n",
    "gs_svm = GridSearchCV(pipe_svm, {\"clf__C\":[0.3, 1.0, 3.0]}, scoring=\"f1_macro\", cv=cv, n_jobs=-1)\n",
    "gs_svm.fit(X_train_f, y_train)\n",
    "\n",
    "# MODEL 3: RANDOM FOREST\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500, max_depth=None, min_samples_leaf=1,\n",
    "    class_weight=\"balanced_subsample\", random_state=42\n",
    ")\n",
    "\n",
    "# Collects summaries to print\n",
    "rows = []\n",
    "rows.append(evaluate(\"LogReg (scaled, balanced)\", gs_lr.best_estimator_))\n",
    "rows.append(evaluate(\"LinearSVC (scaled, balanced)\", gs_svm.best_estimator_))\n",
    "rows.append(evaluate(\"RandomForest (balanced_subsample)\", rf))\n",
    "\n",
    "# Prints summaries, also outputs best parameters for function\n",
    "summary = pd.DataFrame(rows, columns=[\"model\",\"test_accuracy\",\"test_macro_f1\"]).sort_values(\"test_macro_f1\", ascending=False)\n",
    "print(\"Summaries (sorted on macro_f1)\")\n",
    "print(summary)\n",
    "print(\"\\nBest params:\")\n",
    "print(\"- LogReg:\", gs_lr.best_params_)\n",
    "print(\"- LinearSVC:\", gs_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100508a-ae36-4b14-9b6d-c260c6356157",
   "metadata": {},
   "source": [
    "**Train and evaluate three models: LogReg, LinearSVM, RF (ONLY OPENL3 FEATURES, DROP ESSENTIA FEATURES)**\n",
    "\n",
    "\n",
    "Takes a bit of time to run (couple of minutes), mostly informative to compare with the previous models.\n",
    "Code remains the same except for which functions are kept, rest is copied and pasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "075e1e72-759a-4009-80df-83a940f79d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (features): (796, 512) (199, 512)\n",
      "\n",
      "=== LogReg (scaled, balanced) ===\n",
      "Accuracy: 0.17587939698492464\n",
      "Macro-F1: 0.1689376750574134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.07      0.08        28\n",
      "           1       0.09      0.10      0.10        30\n",
      "           2       0.28      0.25      0.26        40\n",
      "           3       0.20      0.22      0.21        23\n",
      "           4       0.26      0.30      0.28        27\n",
      "           5       0.11      0.10      0.11        20\n",
      "           6       0.15      0.16      0.16        31\n",
      "\n",
      "    accuracy                           0.18       199\n",
      "   macro avg       0.17      0.17      0.17       199\n",
      "weighted avg       0.17      0.18      0.17       199\n",
      "\n",
      "\n",
      "=== LinearSVC (scaled, balanced) ===\n",
      "Accuracy: 0.21608040201005024\n",
      "Macro-F1: 0.20347968696657567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.07      0.09        28\n",
      "           1       0.23      0.27      0.25        30\n",
      "           2       0.28      0.30      0.29        40\n",
      "           3       0.18      0.22      0.20        23\n",
      "           4       0.19      0.19      0.19        27\n",
      "           5       0.21      0.15      0.18        20\n",
      "           6       0.23      0.26      0.24        31\n",
      "\n",
      "    accuracy                           0.22       199\n",
      "   macro avg       0.20      0.21      0.20       199\n",
      "weighted avg       0.21      0.22      0.21       199\n",
      "\n",
      "\n",
      "=== RandomForest (balanced_subsample) ===\n",
      "Accuracy: 0.2914572864321608\n",
      "Macro-F1: 0.24161962657403388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.18      0.18        28\n",
      "           1       0.27      0.13      0.18        30\n",
      "           2       0.37      0.78      0.50        40\n",
      "           3       0.31      0.17      0.22        23\n",
      "           4       0.25      0.19      0.21        27\n",
      "           5       0.30      0.15      0.20        20\n",
      "           6       0.21      0.19      0.20        31\n",
      "\n",
      "    accuracy                           0.29       199\n",
      "   macro avg       0.27      0.26      0.24       199\n",
      "weighted avg       0.27      0.29      0.26       199\n",
      "\n",
      "Summaries (sorted on macro_f1)\n",
      "                               model  test_accuracy  test_macro_f1\n",
      "2  RandomForest (balanced_subsample)       0.291457       0.241620\n",
      "1       LinearSVC (scaled, balanced)       0.216080       0.203480\n",
      "0          LogReg (scaled, balanced)       0.175879       0.168938\n",
      "\n",
      "Best params:\n",
      "- LogReg: {'clf__C': 0.3}\n",
      "- LinearSVC: {'clf__C': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Keep ONLY L3 embeddings (e0...e511)\n",
    "def keep_l3_embeddings(df):\n",
    "    def is_l3(col):\n",
    "        if not col.startswith(\"e\"): \n",
    "            return False\n",
    "        suf = col[1:]\n",
    "        if not suf.isdigit(): \n",
    "            return False\n",
    "        idx = int(suf)\n",
    "        return 0 <= idx <= 511\n",
    "    l3_cols = [c for c in df.columns if is_l3(c)]\n",
    "    return df[l3_cols]\n",
    "\n",
    "X_train_f = keep_l3_embeddings(X_train)\n",
    "X_test_f  = keep_l3_embeddings(X_test)\n",
    "\n",
    "print(\"Shapes (features):\", X_train_f.shape, X_test_f.shape)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate(name, est):\n",
    "    est.fit(X_train_f, y_train)\n",
    "    y_pred = est.predict(X_test_f)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mf1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Macro-F1:\", mf1)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0)) \n",
    "    return name, acc, mf1\n",
    "\n",
    "# MODEL 1: LOGISTIC REGRESSION\n",
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", LogisticRegression(max_iter=4000, class_weight=\"balanced\", solver=\"lbfgs\", random_state=42)),\n",
    "])\n",
    "gs_lr = GridSearchCV(pipe_lr, {\"clf__C\":[0.3, 1.0, 3.0]}, scoring=\"f1_macro\", cv=cv, n_jobs=-1)\n",
    "gs_lr.fit(X_train_f, y_train)\n",
    "\n",
    "# MODEL 2: LINEAR SVM\n",
    "pipe_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LinearSVC(C=1.0, class_weight=\"balanced\", random_state=42)),\n",
    "])\n",
    "gs_svm = GridSearchCV(pipe_svm, {\"clf__C\":[0.3, 1.0, 3.0]}, scoring=\"f1_macro\", cv=cv, n_jobs=-1)\n",
    "gs_svm.fit(X_train_f, y_train)\n",
    "\n",
    "# MODEL 3: RANDOM FOREST\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500, max_depth=None, min_samples_leaf=1,\n",
    "    class_weight=\"balanced_subsample\", random_state=42\n",
    ")\n",
    "\n",
    "# Collects summaries to print\n",
    "rows = []\n",
    "rows.append(evaluate(\"LogReg (scaled, balanced)\", gs_lr.best_estimator_))\n",
    "rows.append(evaluate(\"LinearSVC (scaled, balanced)\", gs_svm.best_estimator_))\n",
    "rows.append(evaluate(\"RandomForest (balanced_subsample)\", rf))\n",
    "\n",
    "# Prints summaries, also outputs best parameters for function\n",
    "summary = pd.DataFrame(rows, columns=[\"model\",\"test_accuracy\",\"test_macro_f1\"]).sort_values(\"test_macro_f1\", ascending=False)\n",
    "print(\"Summaries (sorted on macro_f1)\")\n",
    "print(summary)\n",
    "print(\"\\nBest params:\")\n",
    "print(\"- LogReg:\", gs_lr.best_params_)\n",
    "print(\"- LinearSVC:\", gs_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f45d7c-cf55-4cba-8f84-31eea65144e0",
   "metadata": {},
   "source": [
    "**Train and evaluate three models: LogReg, LinearSVM, RF (ALL FEATURES L3 AND ESSENTIA)**\n",
    "\n",
    "\n",
    "Uses ALL the features that are in the dataset, without PCA or feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bac60b2e-3864-45a8-b39a-c6a79c636864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (features): (796, 595) (199, 595)\n",
      "\n",
      "=== LogReg (scaled, balanced) ===\n",
      "Accuracy: 0.20100502512562815\n",
      "Macro-F1: 0.19173698241494855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.11      0.11        28\n",
      "           1       0.12      0.10      0.11        30\n",
      "           2       0.35      0.35      0.35        40\n",
      "           3       0.18      0.17      0.18        23\n",
      "           4       0.21      0.26      0.23        27\n",
      "           5       0.21      0.25      0.23        20\n",
      "           6       0.14      0.13      0.14        31\n",
      "\n",
      "    accuracy                           0.20       199\n",
      "   macro avg       0.19      0.20      0.19       199\n",
      "weighted avg       0.20      0.20      0.20       199\n",
      "\n",
      "\n",
      "=== LinearSVC (scaled, balanced) ===\n",
      "Accuracy: 0.19597989949748743\n",
      "Macro-F1: 0.183676715309054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.14      0.14        28\n",
      "           1       0.19      0.20      0.19        30\n",
      "           2       0.31      0.33      0.32        40\n",
      "           3       0.09      0.09      0.09        23\n",
      "           4       0.23      0.26      0.25        27\n",
      "           5       0.18      0.15      0.16        20\n",
      "           6       0.14      0.13      0.14        31\n",
      "\n",
      "    accuracy                           0.20       199\n",
      "   macro avg       0.18      0.18      0.18       199\n",
      "weighted avg       0.19      0.20      0.19       199\n",
      "\n",
      "\n",
      "=== RandomForest (balanced_subsample) ===\n",
      "Accuracy: 0.2864321608040201\n",
      "Macro-F1: 0.23338093479981223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.11      0.12        28\n",
      "           1       0.28      0.17      0.21        30\n",
      "           2       0.35      0.78      0.48        40\n",
      "           3       0.33      0.22      0.26        23\n",
      "           4       0.44      0.30      0.36        27\n",
      "           5       0.10      0.05      0.07        20\n",
      "           6       0.15      0.13      0.14        31\n",
      "\n",
      "    accuracy                           0.29       199\n",
      "   macro avg       0.26      0.25      0.23       199\n",
      "weighted avg       0.26      0.29      0.25       199\n",
      "\n",
      "Summaries (sorted on macro_f1)\n",
      "                               model  test_accuracy  test_macro_f1\n",
      "2  RandomForest (balanced_subsample)       0.286432       0.233381\n",
      "0          LogReg (scaled, balanced)       0.201005       0.191737\n",
      "1       LinearSVC (scaled, balanced)       0.195980       0.183677\n",
      "\n",
      "Best params:\n",
      "- LogReg: {'clf__C': 0.3}\n",
      "- LinearSVC: {'clf__C': 0.3}\n"
     ]
    }
   ],
   "source": [
    "X_train_f = X_train\n",
    "X_test_f  = X_test\n",
    "\n",
    "print(\"Shapes (features):\", X_train_f.shape, X_test_f.shape)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate(name, est):\n",
    "    est.fit(X_train_f, y_train)\n",
    "    y_pred = est.predict(X_test_f)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mf1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Macro-F1:\", mf1)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0)) \n",
    "    return name, acc, mf1\n",
    "\n",
    "# MODEL 1: LOGISTIC REGRESSION\n",
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", LogisticRegression(max_iter=4000, class_weight=\"balanced\", solver=\"lbfgs\", random_state=42)),\n",
    "])\n",
    "gs_lr = GridSearchCV(pipe_lr, {\"clf__C\":[0.3, 1.0, 3.0]}, scoring=\"f1_macro\", cv=cv, n_jobs=-1)\n",
    "gs_lr.fit(X_train_f, y_train)\n",
    "\n",
    "# MODEL 2: LINEAR SVM\n",
    "pipe_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LinearSVC(C=1.0, class_weight=\"balanced\", random_state=42)),\n",
    "])\n",
    "gs_svm = GridSearchCV(pipe_svm, {\"clf__C\":[0.3, 1.0, 3.0]}, scoring=\"f1_macro\", cv=cv, n_jobs=-1)\n",
    "gs_svm.fit(X_train_f, y_train)\n",
    "\n",
    "# MODEL 3: RANDOM FOREST\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500, max_depth=None, min_samples_leaf=1,\n",
    "    class_weight=\"balanced_subsample\", random_state=42\n",
    ")\n",
    "\n",
    "# Collects summaries to print\n",
    "rows = []\n",
    "rows.append(evaluate(\"LogReg (scaled, balanced)\", gs_lr.best_estimator_))\n",
    "rows.append(evaluate(\"LinearSVC (scaled, balanced)\", gs_svm.best_estimator_))\n",
    "rows.append(evaluate(\"RandomForest (balanced_subsample)\", rf))\n",
    "\n",
    "# Prints summaries, also outputs best parameters for function\n",
    "summary = pd.DataFrame(rows, columns=[\"model\",\"test_accuracy\",\"test_macro_f1\"]).sort_values(\"test_macro_f1\", ascending=False)\n",
    "print(\"Summaries (sorted on macro_f1)\")\n",
    "print(summary)\n",
    "print(\"\\nBest params:\")\n",
    "print(\"- LogReg:\", gs_lr.best_params_)\n",
    "print(\"- LinearSVC:\", gs_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648b621-651d-4731-800c-7c9cc87334bb",
   "metadata": {},
   "source": [
    "**RANDOM FOREST WITH PCA**\n",
    "\n",
    "\n",
    "RF is clearly the most succesful option, so I decided to continue with that to try PCA. (I also tried other options but I did not paste them here because they were really unsuccesful.) Again, I used a 5 fold CV. The PCA doesnt really seem to make a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90d43190-5e09-42e7-bb65-047b47fd9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (features): (796, 595) (199, 595)\n",
      "\n",
      "Best params: {'clf__max_depth': 20, 'clf__min_samples_leaf': 2, 'clf__n_estimators': 400, 'pca__n_components': 64}\n",
      "Best CV Macro-F1: 0.244\n",
      "\n",
      " RandomForest + PCA\n",
      "Accuracy: 0.291\n",
      "Macro-F1: 0.243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.21      0.21        28\n",
      "           1       0.07      0.03      0.05        30\n",
      "           2       0.38      0.72      0.50        40\n",
      "           3       0.33      0.17      0.23        23\n",
      "           4       0.43      0.37      0.40        27\n",
      "           5       0.22      0.10      0.14        20\n",
      "           6       0.16      0.19      0.18        31\n",
      "\n",
      "    accuracy                           0.29       199\n",
      "   macro avg       0.26      0.26      0.24       199\n",
      "weighted avg       0.26      0.29      0.26       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "X_train_f = X_train\n",
    "X_test_f  = X_test\n",
    "print(\"Shapes (features):\", X_train_f.shape, X_test_f.shape)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Random Forest with PCA\n",
    "pipe_rf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA()),\n",
    "    (\"clf\", RandomForestClassifier(class_weight=\"balanced_subsample\", random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [32, 64, 128],\n",
    "    \"clf__n_estimators\": [400],\n",
    "    \"clf__max_depth\": [None, 20],\n",
    "    \"clf__min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_rf, param_grid, scoring=\"f1_macro\", cv=cv, n_jobs=-1, verbose=0)\n",
    "gs.fit(X_train_f, y_train)\n",
    "\n",
    "best = gs.best_estimator_\n",
    "print(\"\\n Best params:\", gs.best_params_)\n",
    "print(\"Best CV Macro-F1:\", round(gs.best_score_, 3))\n",
    "\n",
    "y_pred = best.predict(X_test_f)\n",
    "print(\"\\n RandomForest + PCA\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Macro-F1:\", round(f1_score(y_test, y_pred, average='macro'), 3))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
