{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc874b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a67bb-4880-43f3-866d-610b765eba6f",
   "metadata": {},
   "source": [
    "### Load and explore data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357a8399-5f65-4af4-8b7b-7a252f91be97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (796, 595)\n",
      "Test shape: (199, 595)\n",
      "\n",
      "Label distribution in training set:\n",
      "y\n",
      "2    0.201005\n",
      "6    0.154523\n",
      "1    0.153266\n",
      "0    0.141960\n",
      "4    0.136935\n",
      "3    0.115578\n",
      "5    0.096734\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train = pd.read_csv(\"../data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"../data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\").squeeze()\n",
    "y_test = pd.read_csv(\"../data/y_test.csv\").squeeze()\n",
    "\n",
    "# Print exploratory dataset information\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"\\nLabel distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc81645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_l3_embeddings(df):\n",
    "    def is_l3(col):\n",
    "        if not col.startswith(\"e\"): return False\n",
    "        suf = col[1:]\n",
    "        if not suf.isdigit(): return False\n",
    "        idx = int(suf)\n",
    "        return 0 <= idx <= 511\n",
    "    cols_to_drop = [c for c in df.columns if is_l3(c)]\n",
    "    return df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "X_train_f = drop_l3_embeddings(X_train)\n",
    "X_test_f  = drop_l3_embeddings(X_test)\n",
    "\n",
    "print(\"Shapes (features):\", X_train_f.shape, X_test_f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44a599-8e32-4240-8a6a-d554fe654e38",
   "metadata": {},
   "source": [
    "### Train and evaluate two baselines: 1) majority and 2) random classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a94d8f5-e773-4216-a8de-0c7737efc6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAJORITY BASELINE\n",
      "Accuracy: 0.20100502512562815\n",
      "Macro-F1: 0.04781829049611476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.20      1.00      0.33        40\n",
      "           3       0.00      0.00      0.00        23\n",
      "           4       0.00      0.00      0.00        27\n",
      "           5       0.00      0.00      0.00        20\n",
      "           6       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.20       199\n",
      "   macro avg       0.03      0.14      0.05       199\n",
      "weighted avg       0.04      0.20      0.07       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BASELINE 1: Majority classifier\n",
    "majority_baseline = DummyClassifier(strategy=\"most_frequent\")\n",
    "majority_baseline.fit(X_train, y_train)\n",
    "y_pred_majority = majority_baseline.predict(X_test)\n",
    "\n",
    "print(\"MAJORITY BASELINE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_majority))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred_majority, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred_majority, zero_division=0)) # zero_division=0 is added to avoid annoying warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd132deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM BASELINE\n",
      "Accuracy: 0.1708542713567839\n",
      "Macro-F1: 0.166605585836632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.18      0.19        28\n",
      "           1       0.19      0.17      0.18        30\n",
      "           2       0.23      0.15      0.18        40\n",
      "           3       0.06      0.09      0.07        23\n",
      "           4       0.21      0.22      0.22        27\n",
      "           5       0.09      0.10      0.09        20\n",
      "           6       0.22      0.26      0.24        31\n",
      "\n",
      "    accuracy                           0.17       199\n",
      "   macro avg       0.17      0.17      0.17       199\n",
      "weighted avg       0.18      0.17      0.17       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BASELINE 2: Random classifier\n",
    "random_baseline = DummyClassifier(strategy=\"uniform\", random_state=42)\n",
    "random_baseline.fit(X_train, y_train)\n",
    "y_pred_random = random_baseline.predict(X_test)\n",
    "\n",
    "print(\"RANDOM BASELINE\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_random))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred_random, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred_random, zero_division=0)) # zero_division=0 is added to avoid annoying warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d85ced-5b93-4785-8389-e6772d31c9f6",
   "metadata": {},
   "source": [
    "### Train and evaluate three models: LogReg, LinearSVM, RF on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8770e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate function\n",
    "def evaluate(name, est):\n",
    "    est.fit(X_train_f, y_train)\n",
    "    y_pred = est.predict(X_test_f)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mf1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Macro-F1:\", mf1)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0)) # i am not exactly sure what zero division does but it helped me get rid of an annoying warning\n",
    "    return name, acc, mf1\n",
    "\n",
    "# define CV splits\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8cda49c-b4e2-4a39-b408-e2b85dba9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1: LOGISTIC REGRESSION\n",
    "pipe_lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", LogisticRegression(max_iter=4000, class_weight=\"balanced\", solver=\"lbfgs\", random_state=42)),\n",
    "])\n",
    "gs_lr = GridSearchCV(pipe_lr, {\"clf__C\":[0.3, 1.0, 3.0]}, scoring=\"f1_macro\", cv=cv, n_jobs=-1)\n",
    "gs_lr.fit(X_train_f, y_train)\n",
    "\n",
    "# MODEL 2: LINEAR SVM\n",
    "pipe_svm = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LinearSVC(C=1.0, class_weight=\"balanced\", random_state=42)),\n",
    "])\n",
    "gs_svm = GridSearchCV(pipe_svm, {\"clf__C\":[0.3, 1.0, 3.0]}, scoring=\"f1_macro\", cv=cv, n_jobs=-1)\n",
    "gs_svm.fit(X_train_f, y_train)\n",
    "\n",
    "# MODEL 3: RANDOM FOREST\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500, max_depth=None, min_samples_leaf=1,\n",
    "    class_weight=\"balanced_subsample\", random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ff7208a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogReg (scaled, balanced) ===\n",
      "Accuracy: 0.22110552763819097\n",
      "Macro-F1: 0.21230367287598054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.14      0.15        28\n",
      "           1       0.22      0.17      0.19        30\n",
      "           2       0.36      0.35      0.35        40\n",
      "           3       0.19      0.17      0.18        23\n",
      "           4       0.24      0.30      0.26        27\n",
      "           5       0.21      0.30      0.25        20\n",
      "           6       0.11      0.10      0.10        31\n",
      "\n",
      "    accuracy                           0.22       199\n",
      "   macro avg       0.21      0.22      0.21       199\n",
      "weighted avg       0.22      0.22      0.22       199\n",
      "\n",
      "\n",
      "=== LinearSVC (scaled, balanced) ===\n",
      "Accuracy: 0.20603015075376885\n",
      "Macro-F1: 0.19239616485518127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.11      0.12        28\n",
      "           1       0.20      0.13      0.16        30\n",
      "           2       0.37      0.38      0.37        40\n",
      "           3       0.16      0.17      0.17        23\n",
      "           4       0.21      0.26      0.23        27\n",
      "           5       0.19      0.30      0.23        20\n",
      "           6       0.09      0.06      0.07        31\n",
      "\n",
      "    accuracy                           0.21       199\n",
      "   macro avg       0.19      0.20      0.19       199\n",
      "weighted avg       0.20      0.21      0.20       199\n",
      "\n",
      "\n",
      "=== RandomForest (balanced_subsample) ===\n",
      "Accuracy: 0.31155778894472363\n",
      "Macro-F1: 0.25850430346878245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.18      0.21        28\n",
      "           1       0.21      0.13      0.16        30\n",
      "           2       0.33      0.70      0.45        40\n",
      "           3       0.44      0.30      0.36        23\n",
      "           4       0.37      0.41      0.39        27\n",
      "           5       0.00      0.00      0.00        20\n",
      "           6       0.26      0.23      0.24        31\n",
      "\n",
      "    accuracy                           0.31       199\n",
      "   macro avg       0.27      0.28      0.26       199\n",
      "weighted avg       0.27      0.31      0.28       199\n",
      "\n",
      "Summaries (sorted on macro_f1)\n",
      "                               model  test_accuracy  test_macro_f1\n",
      "2  RandomForest (balanced_subsample)       0.311558       0.258504\n",
      "0          LogReg (scaled, balanced)       0.221106       0.212304\n",
      "1       LinearSVC (scaled, balanced)       0.206030       0.192396\n",
      "\n",
      "Best params:\n",
      "- LogReg: {'clf__C': 1.0}\n",
      "- LinearSVC: {'clf__C': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# Collects summaries to print\n",
    "rows = []\n",
    "rows.append(evaluate(\"LogReg (scaled, balanced)\", gs_lr.best_estimator_))\n",
    "rows.append(evaluate(\"LinearSVC (scaled, balanced)\", gs_svm.best_estimator_))\n",
    "rows.append(evaluate(\"RandomForest (balanced_subsample)\", rf))\n",
    "\n",
    "# Prints summaries, also outputs best parameters for function\n",
    "summary = pd.DataFrame(rows, columns=[\"model\",\"test_accuracy\",\"test_macro_f1\"]).sort_values(\"test_macro_f1\", ascending=False)\n",
    "print(\"Summaries (sorted on macro_f1)\")\n",
    "print(summary)\n",
    "print(\"\\nBest params:\")\n",
    "print(\"- LogReg:\", gs_lr.best_params_)\n",
    "print(\"- LinearSVC:\", gs_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91ba1a",
   "metadata": {},
   "source": [
    "### Train and evaluate RF model with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455e7a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (features): (796, 68) (199, 68)\n"
     ]
    }
   ],
   "source": [
    "# Drop unselected features\n",
    "with open(\"../outputs/selected_features.unbalanced.json\") as f:\n",
    "    selected_features = json.load(f)\n",
    "\n",
    "X_train_fs = X_train_f[selected_features]\n",
    "X_test_fs = X_test_f[selected_features]\n",
    "\n",
    "print(\"Shapes (features):\", X_train_fs.shape, X_test_fs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0555d74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best params: {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "Best CV Macro-F1: 0.222\n",
      "\n",
      " RandomForest + Feature Selection\n",
      "Accuracy: 0.327\n",
      "Macro-F1: 0.286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.21      0.24        28\n",
      "           1       0.35      0.23      0.28        30\n",
      "           2       0.35      0.72      0.47        40\n",
      "           3       0.39      0.30      0.34        23\n",
      "           4       0.28      0.30      0.29        27\n",
      "           5       0.29      0.10      0.15        20\n",
      "           6       0.32      0.19      0.24        31\n",
      "\n",
      "    accuracy                           0.33       199\n",
      "   macro avg       0.32      0.30      0.29       199\n",
      "weighted avg       0.32      0.33      0.30       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_rf = Pipeline([\n",
    "    (\"clf\", RandomForestClassifier(class_weight=\"balanced_subsample\", random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__n_estimators\": [150, 175, 200],\n",
    "    \"clf__max_depth\": [None, 20, 40],\n",
    "    \"clf__min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_rf, param_grid, scoring=\"f1_macro\", cv=cv, n_jobs=-1, verbose=0)\n",
    "gs.fit(X_train_fs, y_train)\n",
    "\n",
    "best = gs.best_estimator_\n",
    "print(\"\\n Best params:\", gs.best_params_)\n",
    "print(\"Best CV Macro-F1:\", round(gs.best_score_, 3))\n",
    "\n",
    "y_pred = best.predict(X_test_fs)\n",
    "print(\"\\n RandomForest + Feature Selection\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Macro-F1:\", round(f1_score(y_test, y_pred, average='macro'), 3))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12048236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../outputs/best_rf_model.pkl']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best RF model\n",
    "best_rf = gs.best_estimator_\n",
    "joblib.dump(best_rf, \"../outputs/best_rf_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df573878",
   "metadata": {},
   "source": [
    "### Train and evaluate RF model (with response_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3631730b",
   "metadata": {},
   "source": [
    "#### Prepare dataset with response_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b80ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_all= pd.read_csv(\"../data/combined_openl3_audiofeatures.csv\")\n",
    "df_r = drop_l3_embeddings(df_r_all)\n",
    "df_r = df_r.drop(columns=\"track_id\")\n",
    "\n",
    "df_r['strategy'] = df_r['strategy'].apply(\n",
    "    lambda s: literal_eval(s) if isinstance(s, str) and s.strip().startswith('[') else s\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "db8806ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multi_strategies(x):\n",
    "    \"\"\"\n",
    "    If songs occur more than once, but for the same strategy (e.g. [('solace', 2)]) keep the strategy\n",
    "    \"\"\"\n",
    "    if isinstance(x,str):\n",
    "        # keep current x\n",
    "        return x\n",
    "    elif isinstance(x,list) and len(x) == 1:\n",
    "        new_x = x[0][0]\n",
    "        return new_x\n",
    "    elif isinstance(x,list) and len(x) > 1:\n",
    "        return np.nan\n",
    "\n",
    "df_r['strategy'] = df_r['strategy'].apply(process_multi_strategies)\n",
    "\n",
    "# drop tracks corresponding to multiple strategies\n",
    "df_r = df_r.dropna(subset=['strategy'])\n",
    "\n",
    "X_r = df_r.drop(columns='strategy')\n",
    "y_r = df_r['strategy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a3e90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode strategies into numerical labels\n",
    "label_mapping = { \n",
    "    0:'discharge', \n",
    "    1:'diversion', \n",
    "    2:'entertainment', \n",
    "    3:'mental_work',\n",
    "    4:'revival', \n",
    "    5:'solace', \n",
    "    6:'strong_sensation'\n",
    "}\n",
    "\n",
    "inverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "y_r_enc = y_r.map(inverse_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c66e596d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (796, 70)\n",
      "Test shape: (199, 70)\n",
      "\n",
      "Label distribution in training set:\n",
      "strategy\n",
      "2    0.201005\n",
      "6    0.154523\n",
      "1    0.153266\n",
      "0    0.141960\n",
      "4    0.136935\n",
      "3    0.115578\n",
      "5    0.096734\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_r, y_r_enc, train_size=0.8, random_state=42, shuffle=True, stratify=y_r)\n",
    "\n",
    "print(\"Train shape:\", X_train_r.shape)\n",
    "print(\"Test shape:\", X_test_r.shape)\n",
    "print(\"\\nLabel distribution in training set:\")\n",
    "print(y_train_r.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe5b3f",
   "metadata": {},
   "source": [
    "#### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2f0d495c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best params: {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 170}\n",
      "Best CV Macro-F1: 0.219\n",
      "\n",
      " RandomForest with Response ID\n",
      "Accuracy: 0.281\n",
      "Macro-F1: 0.235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.11      0.13        28\n",
      "           1       0.16      0.10      0.12        30\n",
      "           2       0.32      0.68      0.44        40\n",
      "           3       0.43      0.26      0.32        23\n",
      "           4       0.26      0.30      0.28        27\n",
      "           5       0.14      0.05      0.07        20\n",
      "           6       0.32      0.26      0.29        31\n",
      "\n",
      "    accuracy                           0.28       199\n",
      "   macro avg       0.26      0.25      0.24       199\n",
      "weighted avg       0.26      0.28      0.25       199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_cols = X_train_r.select_dtypes(include=['object', 'category', 'string']).columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", RandomForestClassifier(class_weight=\"balanced_subsample\", random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__n_estimators\": [130, 150, 170, 190],\n",
    "    \"clf__max_depth\": [None, 20, 40],\n",
    "    \"clf__min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe_rf, param_grid, scoring=\"f1_macro\", cv=cv, n_jobs=-1, verbose=0)\n",
    "gs.fit(X_train_r, y_train_r)\n",
    "\n",
    "best = gs.best_estimator_\n",
    "print(\"\\n Best params:\", gs.best_params_)\n",
    "print(\"Best CV Macro-F1:\", round(gs.best_score_, 3))\n",
    "\n",
    "y_pred = best.predict(X_test_r)\n",
    "print(\"\\n RandomForest with Response ID\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_r, y_pred), 3))\n",
    "print(\"Macro-F1:\", round(f1_score(y_test_r, y_pred, average='macro'), 3))\n",
    "print(classification_report(y_test_r, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
